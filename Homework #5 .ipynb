{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import autograd.numpy as np\n",
    "from sklearn.linear_model import *\n",
    "# from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "# import matplotlib.pyplot as plt\n",
    "from autograd import grad\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emp_risk(theta,x,y):\n",
    "    # X=np.ones_like(x)\n",
    "    X=np.column_stack((np.ones_like(y), x))\n",
    "    y_pred=X @ theta.T \n",
    "    return np.mean(huber_loss(y,y_pred))\n",
    "def huber_loss(e, d):\n",
    "    return (abs(e)<=d)*e**2/2 + (e>d)*d*(abs(e)-d/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_x,data_y=load_diabetes(return_X_y=True,as_frame=False)\n",
    "# print(len(data_x))\n",
    "# print(len(data_y))\n",
    "# print(data_x)\n",
    "# print(data_y)\n",
    "train_data_x=data_x[:-20]\n",
    "test_data_x=data_x[-20:]\n",
    "\n",
    "train_data_y=data_y[:-20]\n",
    "test_data_y=data_y[-20:]\n",
    "# print(np.array(train_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     fun: -7.182004773314065e+210\n     jac: array([ 3.78997790e+105,  1.65069291e+102, -4.16428406e+101,\n        2.08906078e+102,  1.45473268e+102, -1.78117997e+102,\n       -1.81542317e+102, -2.17659397e+102,  7.11166332e+101,\n        9.55079839e+101, -1.50366413e+102])\n message: 'Desired error not necessarily achieved due to precision loss.'\n    nfev: 3900\n     nit: 35\n    njev: 3888\n  status: 2\n success: False\n       x: array([-3.78993796e+105, -1.68682112e+103, -2.43838548e+102,\n       -4.84209309e+103, -3.64653634e+103, -1.54363279e+103,\n       -1.22256735e+103,  3.31118166e+103, -3.53436749e+103,\n       -4.60388854e+103, -2.93143869e+103])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#Q1\n",
    "theta_0 = np.array([0,0,0,0,0,0,0,0,0,0,0])#11\n",
    "# theta_0 = np.array([0,0,0,0,0,0,0,0,0,0])#10\n",
    "\n",
    "grad_fun2=grad(emp_risk)\n",
    "# res2=minimize(emp_risk,theta_0,(train_data_x,train_data_y),method='CG',jac=grad_fun2,options={'maxiter':5000})\n",
    "res2=minimize(emp_risk,theta_0,(train_data_x,train_data_y),method='CG',jac=grad_fun2)\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "intercept_: 151.90824174375456\ncoef_: [ -16.06219252 -290.82121004  494.20822613  360.0538525  -668.46352508\n  352.1321829    12.44998438  176.14693466  721.56117076   53.03320835]\n"
    }
   ],
   "source": [
    "# Q2\n",
    "huber = HuberRegressor(alpha=0).fit(train_data_x, train_data_y)\n",
    "huber.get_params(deep=1)\n",
    "print('intercept_:',huber.intercept_)\n",
    "print('coef_:',huber.coef_)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}